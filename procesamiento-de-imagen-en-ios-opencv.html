
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="captura-ios.html">
      
      
        <link rel="next" href="reproduccion-android.html">
      
      <link rel="icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.1.1">
    
    
      
        <title>Procesamiento de imágenes en iOS - OpenCV - Gráficos y Multimedia</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/main.402914a4.min.css">
      
        
        <link rel="stylesheet" href="assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="Indigo" data-md-color-accent="Indigo">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#procesamiento-de-imagenes-en-ios-opencv" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href="index.html" title="Gráficos y Multimedia" class="md-header__button md-logo" aria-label="Gráficos y Multimedia" data-md-component="logo">
      
  <img src="imagenes/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Gráficos y Multimedia
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Procesamiento de imágenes en iOS - OpenCV
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Búsqueda" placeholder="Búsqueda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Buscar">
        
        <button type="reset" class="md-search__icon md-icon" title="Limpiar" aria-label="Limpiar" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando búsqueda
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Gráficos y Multimedia" class="md-nav__button md-logo" aria-label="Gráficos y Multimedia" data-md-component="logo">
      
  <img src="imagenes/logo.png" alt="logo">

    </a>
    Gráficos y Multimedia
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        Introducción
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="formatos.html" class="md-nav__link">
        Formatos de audio y vídeo
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="streaming.html" class="md-nav__link">
        Difusión de medios
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="unity.html" class="md-nav__link">
        El motor Unity
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="graficos-android.html" class="md-nav__link">
        Gráficos de alto rendimiento en Android
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="graficos-ios.html" class="md-nav__link">
        Gráficos en iOS
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="reproduccion-ios.html" class="md-nav__link">
        Reproducción de medios en iOS
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="captura-ios.html" class="md-nav__link">
        Captura y procesamiento de medios en iOS
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Procesamiento de imágenes en iOS - OpenCV
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="procesamiento-de-imagen-en-ios-opencv.html" class="md-nav__link md-nav__link--active">
        Procesamiento de imágenes en iOS - OpenCV
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#opencv" class="md-nav__link">
    OpenCV
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#opencv-en-ios" class="md-nav__link">
    OpenCV en iOS
  </a>
  
    <nav class="md-nav" aria-label="OpenCV en iOS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#enlazando-la-libreria-opencv-en-nuestro-proyecto" class="md-nav__link">
    Enlazando la librería OpenCV en nuestro proyecto
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#primer-ejemplo-conversion-imagen-a-escala-de-grises" class="md-nav__link">
    Primer ejemplo: Conversión imagen a escala de grises
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#otros-ejemplos" class="md-nav__link">
    Otros ejemplos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detector-de-caras" class="md-nav__link">
    Detector de caras
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#captura-de-video" class="md-nav__link">
    Captura de vídeo
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ejercicios" class="md-nav__link">
    Ejercicios
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="reproduccion-android.html" class="md-nav__link">
        Reproducción de medios en Android
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="captura-android.html" class="md-nav__link">
        Captura de medios en Android
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="procesamiento-android.html" class="md-nav__link">
        Emisión de medios
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="mirroring.html" class="md-nav__link">
        Reproducción en dispositivos externos
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="adobe-air.html" class="md-nav__link">
        Aplicaciones Adobe Air
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="habla-android.html" class="md-nav__link">
        Síntesis y reconocimiento del habla
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#opencv" class="md-nav__link">
    OpenCV
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#opencv-en-ios" class="md-nav__link">
    OpenCV en iOS
  </a>
  
    <nav class="md-nav" aria-label="OpenCV en iOS">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#enlazando-la-libreria-opencv-en-nuestro-proyecto" class="md-nav__link">
    Enlazando la librería OpenCV en nuestro proyecto
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#primer-ejemplo-conversion-imagen-a-escala-de-grises" class="md-nav__link">
    Primer ejemplo: Conversión imagen a escala de grises
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#otros-ejemplos" class="md-nav__link">
    Otros ejemplos
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#detector-de-caras" class="md-nav__link">
    Detector de caras
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#captura-de-video" class="md-nav__link">
    Captura de vídeo
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ejercicios" class="md-nav__link">
    Ejercicios
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="procesamiento-de-imagenes-en-ios-opencv">Procesamiento de imágenes en iOS: OpenCV<a class="headerlink" href="#procesamiento-de-imagenes-en-ios-opencv" title="Permanent link">&para;</a></h1>
<p><img alt="" src="imagenes/opencv/ios_opencv_logo.png" /></p>
<p>En esta sección vamos a ver como llevar a cabo procesamiento de imágenes en iOS utilizando la librería de visión por computador <strong>OpenCV</strong>.</p>
<h2 id="opencv">OpenCV<a class="headerlink" href="#opencv" title="Permanent link">&para;</a></h2>
<p><a href="http://opencv.org/">OpenCV</a> es una librería de código abierto para visión por computador. El principal objetivo de esta librería es ofrecer algoritmos de visión artificial que funcionen en tiempo real. Originalmente OpenCV fue desarrollada por el departamento de investigación de Intel, pero más tarde recibió soporte de la empresa <a href="http://www.willowgarage.com/">Willow Garage</a> y actualmente es mantenido por la empresa <a href="https://vk.com/itseez">Itseez</a>. Se trata de una librería multi-plataforma (Windows, Linux, MacOSX, iOS, Android, ... )y se puede utilizar libremente al ser desarrollada bajo una licencia de código abierto BSD. </p>
<p>Áreas de aplicación librería OpenCV:
* Egomotion
* Sistema de detección/reconocimiento facial
* Reconocimiento de gestos
* Segmentación
* Calibración de cámaras
* Tracking
* Algoritmos estéreo
* Structure from Motion (SfM)
* Retoque de imágenes (Balance de blancos, HDR, constrate, etc)
* ...</p>
<p>Además, OpenCV cuenta con una librería de aprendizaje automático que contiene métodos tradicionales de clasificación y regresión:
* Arboles de decisión
* Redes neuronales artificiales
* k-vecinos más cercanos
* Random forest
* Support vector machine (SVM)
* ...</p>
<h2 id="opencv-en-ios">OpenCV en iOS<a class="headerlink" href="#opencv-en-ios" title="Permanent link">&para;</a></h2>
<p>OpenCV es una librería escrita en C/C++, por lo que utilizando Objective-C no hay mucho problema para su integración en iOS. Sin embargo, con Swift la cosa es ligeramente más complicada, y necesitaremos utilizar una cabecera puente en nuestro proyecto para acceder a funciones de OpenCV. Por ello tendremos que escribir un poco de Objective-C++ en nuestros proyectos.</p>
<p><img alt="" src="imagenes/opencv/ios_opencv_swift_objc%2B%2B.png" /></p>
<h3 id="enlazando-la-libreria-opencv-en-nuestro-proyecto">Enlazando la librería OpenCV en nuestro proyecto<a class="headerlink" href="#enlazando-la-libreria-opencv-en-nuestro-proyecto" title="Permanent link">&para;</a></h3>
<p>Para utilizar OpenCV en iOS tendremos que descargarnos la versión correspondiente para esta plataforma de la web oficial. En concreto vamos a utilizar la versión 2.4.13 para iOS. <a href="https://sourceforge.net/projects/opencvlibrary/files/opencv-ios/2.4.13/opencv2.framework.zip/download">Enlace descarga</a>.</p>
<p>El siguiente paso será crear un nuevo proyecto en Xcode y añadir las librerías necesarias para usar OpenCV en nuestro proyecto. Creamos un proyecto nuevo (Single View) y simplemente arrastramos a la ventana donde se muestran los ficheros del proyecto el fichero <code>opencv2.framework</code>, al hacer esto nos aparecerá un diálogo para importarlo en el proyecto. Marcamos la opción copiar si es necesario.</p>
<p><img alt="" src="imagenes/opencv/ios_opencv_import_lib.png" /></p>
<p>Con este paso ya tendremos OpenCV añadido a nuestro proyecto, pero para poder utilizarlo tendremos que crear una cabecera puente (Bridging header), que nos permita utilizar código Objetive-C++ desde código Swift. Para crear la cabecera puente, vamos a File &gt; New &gt; File (⌘N) y en iOS &gt; Source seleccionamos <code>Cocoa Touch Class</code>. Lo llamaremos OpenCVWrapper, en este fichero escribiremos el código que servirá de envoltorio para utilizar funciones OpenCV en Objective-C++. Al crear este fichero Xcode nos sugerirá crear la cabecera puente: <code>nombreproyecto-Bridging-header.h</code>. Todas las librerías que incluyamos desde este fichero header, las clases y métodos definidas en las mismas serán accesibles desde nuestro código en Swift.</p>
<p>Con estos pasos habremos creados tres nuevos ficheros en nuestro proyecto: <code>OpenCVWrapper.h</code>, <code>OpenCVWrapper.m</code> y <code>nombre-proyecto-Bridging-Header.h</code>. Como hemos comentado, la cabecera puente será nuestra interfaz para usar funciones de OpenCV, por lo tanto tenemos que añadir el envoltorio que hemos creado: </p>
<div class="highlight"><pre><span></span><code>#import &quot;OpenCVWrapper.h&quot;
</code></pre></div>
<h3 id="primer-ejemplo-conversion-imagen-a-escala-de-grises">Primer ejemplo: Conversión imagen a escala de grises<a class="headerlink" href="#primer-ejemplo-conversion-imagen-a-escala-de-grises" title="Permanent link">&para;</a></h3>
<p>Con esto ya estamos listos para empezar a utilizar OpenCV en nuestro proyecto, por ello vamos a crear una sencilla aplicación que cargue una imagen y convierta la imagen a escala de grises utilizando la función predefinida en OpenCV `cv::cvtColor(imageMat, gray, CV_RGBA2GRAY);``</p>
<p>Añadimos un ImageView (cargar imagen) y un botón a la interfaz de la apliación que creamos anteriormente. Al pulsar el botón convertiremos la imágen a escala de grises. Para ello, en la clase OpenCVWrapper que creamos anteriormente para utilizar la funcionalidad de la librería escribimos nuestra propia función para convertir a escala de grises. La función tomará como entrada una imagen en formato UIImage, la convertirá a formato OpenCV, cv::Mat, y finalmente se convertirá de vuelta al formato UIImage para su visualizaión.
Para convertir imágenes entre UIImage y el formato de OpenCV, utilizaremos los métodos definidos en las cabeceras:
 * <code>#import "opencv2/highgui/ios.h"</code>
 * <code>#import &lt;opencv2/highgui/cap_ios.h&gt;</code></p>
<p>En estas cabeceras se encuentran definidos métodos para interoperar con tipos de datos propios de iOS.</p>
<p>Convertir una imagen a formato cv::Mat:</p>
<p><code>UIImageToMat(image,imageMat);</code></p>
<p>Convertir formato cv::Mat a UIImage</p>
<p><code>MatToUIImage(gray);</code></p>
<p>Finalmente crearemos una función <code>convertImageToGrayScale</code>en la clase <code>OpenCVWrapper</code>. Esta clase nos servirá de interfaz con OpenCV y la utilizaremos desde nuestro código en Swift</p>
<p><strong>( OpenCVWrapper.mm )</strong>
<div class="highlight"><pre><span></span><code>#import &quot;OpenCVWrapper.h&quot;

@implementation OpenCVWrapper

+(UIImage *) convertImageToGrayscale: (UIImage *)image
{
 cv::Mat imageMat;
 UIImageToMat(image,imageMat);
 if(imageMat.channels() == 1){ return image; }
 cv::Mat gray;
 // Convert the image to grayscale
 cv::cvtColor(imageMat, gray, CV_RGBA2GRAY);
 return MatToUIImage(gray);
}
@end
</code></pre></div></p>
<p><strong>( OpenCVWrapper.h )</strong>
<div class="highlight"><pre><span></span><code>#import &lt;Foundation/Foundation.h&gt;

#import &lt;UIKit/UIKit.h&gt;

// Need this ifdef, so the C++ header won&#39;t confuse Swift
#ifdef __cplusplus
 #import &lt;opencv2/opencv.hpp&gt;
 #import &quot;opencv2/highgui/ios.h&quot;
 #import &lt;opencv2/highgui/cap_ios.h&gt;
#endif

@interface OpenCVWrapper : NSObject

+(UIImage *) convertImageToGrayscale: (UIImage *)Image;

@end
</code></pre></div></p>
<p>Finalmente, desde nuestro código Swift llamaremos a la función <code>convertImageToGrayscale</code> al accionar el botón 'convertir':</p>
<div class="highlight"><pre><span></span><code>@IBAction func botonConvertirGrises(_ sender: UIButton) 
{
    imagen.image = OpenCVWrapper.convertImage(toGrayscale: imagen!.image)
}
</code></pre></div>
<p><img alt="" src="imagenes/opencv/ios_opencv_grayscale.png" /></p>
<h3 id="otros-ejemplos">Otros ejemplos<a class="headerlink" href="#otros-ejemplos" title="Permanent link">&para;</a></h3>
<p>A continuación vamos a ver como aplicar a nuestra imagen otros filtros típicos en procesamiento de imagen. Por ejemplo, un filtro de emborronamiento, del inglés, blur. De igual manera que hicimos anteriormente, creamos una nuevo método en nuestra interfaz <code>OpenCVWrapper</code>. En este caso usaremos una de las funciones de filtrado de OpenCV, se trata de un método para emborronar la imagen: </p>
<p><code>+(UIImage *) blurImage: (UIImage *)Image;</code></p>
<p>El nuevo método quedaría de la siguiente forma:</p>
<div class="highlight"><pre><span></span><code>+(UIImage *) blurImage: (UIImage *)image
{
     cv::Mat imageMat;
     UIImageToMat(image,imageMat);
     cv::Mat blurImage;
     cv::GaussianBlur( imageMat, blurImage, cv::Size( 3, 3 ), 0, 0 );
     return MatToUIImage(blurImage);
}
</code></pre></div>
<p>A continuación vamos a ver otro filtro un poco más complejo, en concreto un filtro detector de bordes, <a href="https://es.wikipedia.org/wiki/Algoritmo_de_Canny">algoritmo de Canny</a>. Este filtro se encuentra implementado en OpenCV y por lo tanto podemos usarlo para procesar nuestras imágenes. </p>
<div class="highlight"><pre><span></span><code> cv::Canny(gray, edges, 0, 50, 3);
</code></pre></div>
<p>Los argumentos que recibe este método son los siguientes:</p>
<ul>
<li>Imagen origen en escala de grises</li>
<li>Imagen salida con los bordes detectados</li>
<li>lowThreshold: umbral inferior para la detección de bordes</li>
<li>highThreshold: umbral superior para la detección de bordes</li>
<li>kernel_size: tamaño de la convolución 2D en las dimensiones X e Y. Por defecto 3.</li>
</ul>
<p><img alt="" src="imagenes/opencv/ios_opencv_edge_detector.png" /></p>
<p>En OpenCV encontramos muchos otras funciones de procesamiento de imágen y visión por computador que podemos utilizar en nuestra aplicación, toda la documentación sobre la librería y métodos disponibles se puede encontrar <a href="http://docs.opencv.org/2.4/index.html">online</a>.</p>
<h3 id="detector-de-caras">Detector de caras<a class="headerlink" href="#detector-de-caras" title="Permanent link">&para;</a></h3>
<p>A continuación, vamos a ver como utilizar OpenCV para poner en funcionamiento un detector de caras en nuestra aplicación móvil. OpenCV implementa clasificadores en cascada para detectar múltiples objetos. En nuestro caso vamos a cargar un modelo para el clasificador que esta entrenado para detectar caras. En concreto usaremos el clasificador basado en las características de Haar. Podeis encontrar más información sobre la implementación de este método en el siguiente <a href="http://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html">enlace</a>. El trabajo original se basa en el siguiente artículo científico:</p>
<div class="highlight"><pre><span></span><code>[Viola01] Paul Viola and Michael J. Jones. Rapid Object Detection using a Boosted Cascade of Simple Features. IEEE CVPR, 2001. 
</code></pre></div>
<p>Para utilizar este método en nuestro proyecto vamos a crear un nuevo wrapper que nos sirva de interfaz para el objeto <code>cv::CascadeClassifier</code>. Este objeto OpenCV nos permitirá cargar un modelo entrenado para la detección de caras así como la detección en sí. Crearemos un método para inicializar el clasificador con el modelo detector de caras.</p>
<div class="highlight"><pre><span></span><code>NSString* cascadePath = [[NSBundle mainBundle] pathForResource:@&quot;haarcascade_frontalface_alt2&quot; ofType:@&quot;xml&quot;];
faceDetector.load([cascadePath UTF8String]);
</code></pre></div>
<p>Podremos descargas este modelo y otros previamente entrenados desde el <a href="https://github.com/opencv/opencv/tree/master/data/haarcascades">repositorio</a> oficial de la librería  OpenCV. Encontramos otros modelos para detectar ojos, personas, tronco superior, etcétera. </p>
<p>Crearemos otro método dentro de nuestro wrapper para llevar a cabo la detección de caras dada una imagen de entrada.</p>
<div class="highlight"><pre><span></span><code>-(UIImage *) detectFaces: (UIImage *)image
</code></pre></div>
<p>Este método contiene toda la lógica necesaria para detectar caras en una imagen utilizando la función </p>
<div class="highlight"><pre><span></span><code>faceDetector.detectMultiScale(gray, faces, 1.1, 2, 0|CV_HAAR_SCALE_IMAGE, cv::Size(30, 30));
</code></pre></div>
<p>Esta función recibe los siguientes parámetros:</p>
<ul>
<li>Imagen de entrada (escala de grises)</li>
<li>Factor de escala: especifica cuanto se escala la imagen en cada iteración</li>
<li>Número mínimo de vecinos: especifica cuantos vecinos (detecciones) como mínimo debe tener una detección para considerarse como válida.</li>
<li><code>CV_HAAR_SCALE_IMAGE</code>: especifica que se escale la imagen y no el detector. Esto mejora el rendimiento del detector.</li>
<li>Tamaño mínimo: tamaño mínimo posible de una cara a detectar en la imágen.</li>
</ul>
<p>El método <code>detectFaces</code> contendría el siguiente código (Se ha eliminado el código para interoperar con UIImage y convertir a escala de grises por claridad):</p>
<div class="highlight"><pre><span></span><code>// Detect faces
std::vector&lt;cv::Rect&gt; faces;
faceDetector.detectMultiScale(gray, faces, 1.1, 2, 0|CV_HAAR_SCALE_IMAGE, cv::Size(30, 30));

// Draw all detected faces
for(unsigned int i = 0; i &lt; faces.size(); i++)
{
    const cv::Rect&amp; face = faces[i];
    // Get top-left and bottom-right corner points
    cv::Point tl(face.x, face.y);
    cv::Point br = tl + cv::Point(face.width, face.height);
    // Draw rectangle around the face
    cv::Scalar magenta = cv::Scalar(255, 0, 255);
    cv::rectangle(cvImage, tl, br, magenta, 4, 8, 0);
}
</code></pre></div>
<p>Como podemos apreciar arriba, una vez detectadas las caras, utilizando funciones OpenCV dibujamos gráficos sobre la imagen que posteriormente visualizaremos en el ImageView de nuestra app móvil.</p>
<p><img alt="" src="imagenes/opencv/ios_opencv_face_detector.png" /></p>
<p>Aunque iOS también tiene su propio detector de caras como hemos visto anteriormente, el clasificador de OpenCV nos ofrece más posibilidades, permitiéndonos detectar más objetos por tantos siendo más flexible. Si no existiese un clasificador pre-entrenado para el tipo de objeto que queremos detectar, siempre podemos entrenar nuestro propio clasificador nuevos propio conjunto de imágenes previamente anotadas. Esta tarea puede requerir de tiempo y esfuerzo en términos de investigación, aunque es factible.</p>
<p>Por último, en OpenCV podemos también ajustar el rendimiento del clasificador, ya que el clasificador en cascada es una técnica costa computacionalmente. Ajustando algunos de los parámetros del método <code>detectMultiScale</code>podemos mejorar el rendimiento, aunque por otro lado la precisión del método podría reducirse. Además de ajustar los parámetros, OpenCV implementa otro tipo de características, denominadas Local Binary Patterns (LBP), que se puede utilizar para el clasificador en cascada. Este tipo de características son más eficientes de computar ya que estan basadas principalmente en cómputos que se pueden llevar a cabo con aritmética entera, siendo por lo tanto más eficientes y funcionando 2-3 veces más rápido que las características de Haar (punto flotante). Otra opción para mejorar el rendimiento podría ser no procesar todos las imágenes de nuestro flujo de vídeo y llevar a cabo algúna técnica de seguimiento entre detecciónes (Optical flow).</p>
<h3 id="captura-de-video">Captura de vídeo<a class="headerlink" href="#captura-de-video" title="Permanent link">&para;</a></h3>
<p>OpenCV también implementa sus clases propias para la captura de vídeo, de forma que nos permite abstraernos a la hora de utilizar la cámara de nuestro dispositivo móvil y utilizar el recurso que tengamos disponible. La clase OpenCV para obtener un flujo de vídeo en nuestra app es <code>CvVideoCamera</code>. Utilizando esta clase podremos facilmente obtener vídeo de la cámara de nuestro dispositivo y además procesarlo usando las distintas funcionalidades que OpenCV nos ofrece.</p>
<p>Para poder utilizar esta clase en nuestro proyecto iOS, tendremos que enlazar las siguientes librerías en el proyecto:</p>
<p><img alt="" src="imagenes/opencv/ios_opencv_cvvideocamera_libraries.png" /></p>
<p>Además, añadiremos la siguiente cabecera en el wrapper de OpenCV: `#import <opencv2/highgui/cap_ios.h>``</p>
<p>Para la utilización de <code>CvVideoCamera</code>en Swift, escribiremos también un wrapper como hicimos anteriormente para las funciones de procesamiento de imagen y detección de caras.</p>
<p>CvVideoCaptureWrapper.mm
<div class="highlight"><pre><span></span><code>// Class extension to adopt the delegate protocol
@interface CvVideoCameraWrapper () &lt;CvVideoCameraDelegate&gt;
{

}
@end

@implementation CvVideoCameraWrapper
{
 ViewController * viewController;
 UIImageView * imageView;
 CvVideoCamera * videoCamera;
}

// Otros métodos para inicializar y procesar imágenes del vídeo
...
</code></pre></div></p>
<p>CvVideoCaptureWrapper.h
<div class="highlight"><pre><span></span><code>// This is a forward declaration; we cannot include *-Swift.h in a header.
@class ViewController;
@interface CvVideoCameraWrapper : NSObject
    -(id)initWithController:(ViewController*)c andImageView (UIImageView*)iv;
@end
</code></pre></div></p>
<p>Finalmente, imlementaremos dos métodos en nuestra clase <code>CvVideoCameraWrapper</code>, un método para inicializar la cámara con las opciones que deseemos, y otro método para llevar a cabo procesamiento del flujo de vídeo de la cámara.</p>
<p>Método inicialización cámara
<div class="highlight"><pre><span></span><code>-(id)initWithController:(ViewController*)c andImageView:(UIImageView*)iv 
{
    viewController = c;
    imageView = iv;
    videoCamera = [[CvVideoCamera alloc] initWithParentView:imageView];

    // ... set up the camera
    videoCamera.delegate = self;
    videoCamera.defaultAVCaptureDevicePosition = AVCaptureDevicePositionBack;
    videoCamera.defaultAVCaptureSessionPreset = AVCaptureSessionPreset640x480;
    videoCamera.defaultAVCaptureVideoOrientation = AVCaptureVideoOrientationLandscapeLeft;
    videoCamera.defaultFPS = 30;
    videoCamera.rotateVideo = !videoCamera.rotateVideo;
    [videoCamera start];
    return self;
}
</code></pre></div></p>
<p>En el método anterior hemos definido las propiedades para el flujo de vídeo a obtener de la cámara: resolución, cámara (frontal o trasera), configuración (por defecto), imágenes por segundo, rotar el vídeo, etcétera. Además, en este método asignamos objetos como el imageView donde vamos a renderizar las imágenes de la cámara y el controlador que se hará cargo de esta vista.</p>
<p>Finalmente, implementaremos el método <code>processImage</code>, el cual se encargará de procesar cada imágen del flujo de vídeo. Podemos aplicar filtros y técnicas como las vistas anteriormente: conversión escala de grises, detección de bordes, suavizado, detección de caras, etcétera.</p>
<div class="highlight"><pre><span></span><code>- (void)processImage:(cv::Mat&amp;)image
{
    // Procesamiento imagen con OpenCV: ejemplo, conversión escala de grises
    cv::cvtColor(image, image, CV_RGBA2GRAY);
}
</code></pre></div>
<h3 id="ejercicios">Ejercicios<a class="headerlink" href="#ejercicios" title="Permanent link">&para;</a></h3>
<p>1.- En primer lugar, crea un nuevo proyecto en Xcode y enlaza la librería OpenCV. Crea las clases envoltorio, así como la librería puente para poder utilizar OpenCV en tu código Swift.</p>
<p>(a) Diseña una interfaz de usuario que contenga inicialmente un <code>ImageView</code> y un botón para convertir una imagen que cargaremos en el <code>imageView</code> a escala de grises.</p>
<p>(b) Implementa en el envoltorio para utilizar OpenCV un método que nos permita convertir una imagen a escala de grises. Al pulsar el botón creado anteriormente se convertirá la imagen a escala de grises.</p>
<p>(c) Implementa un método para la detección de bordes en la imagen que hemos cargado. Para mejorar la detección de líneas es muy común utilizar un filtro de suavizado (emborronamiento) de la imagen antes de llevar a cabo la detección usando el filtro de Canny. Implementa estas dos operaciones en el envoltorio y añade un componente <code>slider</code>que nos permite cambiar los umbrales que utilizamos en el método de Canny. Al mover el slider actualizaremos la imagen con los nuevos resultados.</p>
<p>(d) Añade un nuevo botón a la interfaz que nos permita detectar caras en la imagen. Utilizaremos un clasificador en cascada como el visto anteriormente. Implementa un envoltorio en Objective-C++ para utilizar esta funcionalidad el <code>ViewController</code> (Swift). Dibuja un rectángulo sobre cada una de las caras detectadas, utiliza las funciones de dibujado de formas básicas de OpenCV (<code>cv::rectangle(cvImage, tl, br, magenta, 4, 8, 0);</code>).</p>
<p>2.- Utiliza la clase <code>CvVideoCamera</code> de OpenCV para obtener un flujo de vídeo en nuestra aplicación iOS y procesar las imágenes obtenidas.</p>
<p>(a) Lleva a cabo un procesamiento de extracción de bordes sobre el flujo de vídeo obtenido en tiempo real de la cámara. </p>
<p>(b) Añade un slider a la interfaz de usuario para modificar los parámetros del detector de bordes de Canny y otro slider para cambiar el nivel de suavizado de la imagen. Observa como estos parámetros alteran la imagen resultado.</p>
<p>Para el ejercicio 2 utiliza la plantilla que hemos dejado en el repositorio de la asignatura: <code>plantillas-multimedia-graficos-ios-swift</code>. Nombre proyecto: <code>CapturaVideoOpenCV</code>.</p>
<p>Recuerda que el ejercicio 2 debe desplegarse sobre un dispositivo real, debido a que el emulador no soporta el uso de la cámara.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": ".", "features": [], "search": "assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version": "Seleccionar versi\u00f3n"}}</script>
    
    
      <script src="assets/javascripts/bundle.b78d2936.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>